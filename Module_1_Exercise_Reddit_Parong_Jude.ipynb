{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime\n",
    "import csv\n",
    "import os \n",
    "import requests \n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your exercise do the following:\n",
    "\n",
    "1. Choose a reddit page you want to crawl\n",
    "2. The following fields should be present when you crawl **(10 points)**:\n",
    "    - author\n",
    "    - subreddit\n",
    "    - date created \n",
    "    - number of comments \n",
    "    - score\n",
    "    - submission title \n",
    "    - submission description\n",
    "3. After crawling, save your results to a pandas dataframe **(3 points)**. \n",
    "4. Answer the following questions **(12 points)**:\n",
    "    - How many submissions were you able to gather? \n",
    "    - Who has the most submissions? \n",
    "    - Which submission has the highest score? \n",
    "    - Which submission has the highest number of comments?\n",
    "    - Which day of the week has the most submissions? \n",
    "    \n",
    "**Tip:** _For item#4, recall how to use the aggregation functions in `pandas` like count, value_counts, sum, etc. For getting the day of the week, look into how to get the `dayofweek` from a datetime object in `pandas`. (Hint: You may need to use `pd.to_datetime` to convert your date column...)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utc_to_unix(date):\n",
    "    '''Forces a timestamp into the UTC timezone and converts it to a UNIX epoch'''\n",
    "    return int(date.replace(tzinfo=dt.timezone.utc).timestamp())\n",
    "\n",
    "def unix_to_utc(unix):\n",
    "    '''Converts a UNIX epoch to a UTC Timestamp'''\n",
    "    return datetime.datetime.utcfromtimestamp(unix).strftime('%Y-%m-%d %H:%M:%S')\n",
    "#prepare the API call\n",
    "url = \"https://api.pushshift.io/reddit/submission/search/\"\n",
    "subreddit = 'nosleep' #/r/nosleep\n",
    "fields = ['author', 'subreddit','created_utc','num_comments','score','title','selftext']\n",
    "sort_type = 'created_utc'\n",
    "sort = 'asc'\n",
    "size = 500 \n",
    "\n",
    "#Declare start and end of reddit posts to extract \n",
    "start_date = dt.datetime.strptime(\"2020-04-01\", \"%Y-%m-%d\")\n",
    "end_date = dt.datetime.strptime(\"2020-05-01\", \"%Y-%m-%d\")\n",
    "\n",
    "URL = \"https://api.pushshift.io/reddit/submission/search/\"  #query submissions\n",
    "PARAMS = {\n",
    "    'after': utc_to_unix(start_date)-1, #get dates after April 1, 2020 UTC\n",
    "    'before': utc_to_unix(end_date), #get dates before May 1, 2020 UTC\n",
    "    'sort_type': sort_type, # sort by created_utc\n",
    "    'sort': sort, # sort in descending order\n",
    "    'subreddit': subreddit, # do a search on ProRevenge subreddit\n",
    "    'size': size, # give only 500 search results\n",
    "    'fields': fields  #return only the following fields\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done until 2020-04-01 16:36:19 - Result Size 100 - Total Results Size 100\n",
      "Done until 2020-04-02 08:35:51 - Result Size 100 - Total Results Size 200\n",
      "Done until 2020-04-03 00:42:32 - Result Size 100 - Total Results Size 300\n",
      "Done until 2020-04-03 18:37:58 - Result Size 100 - Total Results Size 400\n",
      "Done until 2020-04-04 15:12:40 - Result Size 100 - Total Results Size 500\n",
      "Done until 2020-04-05 06:34:08 - Result Size 100 - Total Results Size 600\n",
      "Done until 2020-04-06 00:43:33 - Result Size 100 - Total Results Size 700\n",
      "Done until 2020-04-06 18:50:07 - Result Size 100 - Total Results Size 800\n",
      "Done until 2020-04-07 14:46:39 - Result Size 100 - Total Results Size 900\n",
      "Done until 2020-04-08 07:37:51 - Result Size 100 - Total Results Size 1000\n",
      "Done until 2020-04-09 04:12:01 - Result Size 100 - Total Results Size 1100\n",
      "Done until 2020-04-09 21:34:07 - Result Size 100 - Total Results Size 1200\n",
      "Done until 2020-04-10 13:46:35 - Result Size 100 - Total Results Size 1300\n",
      "Done until 2020-04-11 04:42:49 - Result Size 100 - Total Results Size 1400\n",
      "Done until 2020-04-11 22:09:24 - Result Size 100 - Total Results Size 1500\n",
      "Done until 2020-04-12 16:49:52 - Result Size 100 - Total Results Size 1600\n",
      "Done until 2020-04-13 04:11:14 - Result Size 100 - Total Results Size 1700\n",
      "Done until 2020-04-13 22:23:33 - Result Size 100 - Total Results Size 1800\n",
      "Done until 2020-04-14 17:27:22 - Result Size 100 - Total Results Size 1900\n",
      "Done until 2020-04-15 11:49:54 - Result Size 100 - Total Results Size 2000\n",
      "Done until 2020-04-16 05:14:55 - Result Size 100 - Total Results Size 2100\n",
      "Done until 2020-04-16 23:53:47 - Result Size 100 - Total Results Size 2200\n",
      "Done until 2020-04-17 17:45:56 - Result Size 100 - Total Results Size 2300\n",
      "Done until 2020-04-18 12:09:26 - Result Size 100 - Total Results Size 2400\n",
      "Done until 2020-04-19 05:22:15 - Result Size 100 - Total Results Size 2500\n",
      "Done until 2020-04-20 02:14:58 - Result Size 100 - Total Results Size 2600\n",
      "Done until 2020-04-20 18:44:33 - Result Size 100 - Total Results Size 2700\n",
      "Done until 2020-04-21 11:49:52 - Result Size 100 - Total Results Size 2800\n",
      "Done until 2020-04-22 00:43:42 - Result Size 100 - Total Results Size 2900\n",
      "Done until 2020-04-22 18:20:00 - Result Size 100 - Total Results Size 3000\n",
      "Done until 2020-04-23 11:28:14 - Result Size 100 - Total Results Size 3100\n",
      "Done until 2020-04-24 01:37:07 - Result Size 100 - Total Results Size 3200\n",
      "Done until 2020-04-24 17:58:03 - Result Size 100 - Total Results Size 3300\n",
      "Done until 2020-04-25 07:03:55 - Result Size 100 - Total Results Size 3400\n",
      "Done until 2020-04-26 00:01:07 - Result Size 100 - Total Results Size 3500\n",
      "Done until 2020-04-26 15:52:52 - Result Size 100 - Total Results Size 3600\n",
      "Done until 2020-04-27 05:02:38 - Result Size 100 - Total Results Size 3700\n",
      "Done until 2020-04-27 23:12:39 - Result Size 100 - Total Results Size 3800\n",
      "Done until 2020-04-28 13:37:59 - Result Size 100 - Total Results Size 3900\n",
      "Done until 2020-04-29 04:43:43 - Result Size 100 - Total Results Size 4000\n",
      "Done until 2020-04-29 20:45:04 - Result Size 100 - Total Results Size 4100\n",
      "Done until 2020-04-30 14:56:48 - Result Size 100 - Total Results Size 4200\n",
      "Done until 2020-04-30 23:58:10 - Result Size 65 - Total Results Size 4265\n"
     ]
    }
   ],
   "source": [
    "#Setup blank list\n",
    "results = []\n",
    "\n",
    "#loop while date range not fulfilled\n",
    "while PARAMS['after'] < PARAMS['before']:\n",
    "    #use the requests library to query pushshift api\n",
    "    r = requests.get(url = URL, params = PARAMS)\n",
    "    \n",
    "    if r.json()['data'] == []:\n",
    "        break\n",
    "        \n",
    "    #extend list results\n",
    "    results.extend(r.json()['data'])\n",
    "\n",
    "    #change start_time\n",
    "    start_date = r.json()['data'][-1]['created_utc'] # this sets new start time to the last timestamp in the result array\n",
    "    PARAMS['after'] = start_date\n",
    "    print('Done until {} - Result Size {} - Total Results Size {}'.format(unix_to_utc(start_date), len(r.json()['data']), len(results)))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(results)\n",
    "#saves the dataframe for sanity\n",
    "df.to_csv('reddit_nosleep.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpOoKyCaT--</td>\n",
       "      <td>1585699665</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Let me preface this by saying I just moved int...</td>\n",
       "      <td>nosleep</td>\n",
       "      <td>My Mom Checks In On Me When I Sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ak4402</td>\n",
       "      <td>1585701329</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>nosleep</td>\n",
       "      <td>It was just before sunrise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1585701960</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nosleep</td>\n",
       "      <td>The Boy Disappeared into the forest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quebrain</td>\n",
       "      <td>1585702604</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Mother told me to wash the dishes. I complied....</td>\n",
       "      <td>nosleep</td>\n",
       "      <td>We Can Be Better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1585703084</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nosleep</td>\n",
       "      <td>Every single passenger in this train is going ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author  created_utc  num_comments  score  \\\n",
       "0  SpOoKyCaT--   1585699665             8      5   \n",
       "1       ak4402   1585701329             2      2   \n",
       "2    [deleted]   1585701960             2      1   \n",
       "3     quebrain   1585702604             4      1   \n",
       "4    [deleted]   1585703084             0      1   \n",
       "\n",
       "                                            selftext subreddit  \\\n",
       "0  Let me preface this by saying I just moved int...   nosleep   \n",
       "1                                          [removed]   nosleep   \n",
       "2                                                NaN   nosleep   \n",
       "3  Mother told me to wash the dishes. I complied....   nosleep   \n",
       "4                                                NaN   nosleep   \n",
       "\n",
       "                                               title  \n",
       "0                My Mom Checks In On Me When I Sleep  \n",
       "1                      It was just before sunrise...  \n",
       "2             The Boy Disappeared into the forest...  \n",
       "3                                   We Can Be Better  \n",
       "4  Every single passenger in this train is going ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reddit_nosleep.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total April 2020 Submissions: 4265\n"
     ]
    }
   ],
   "source": [
    "# How many submissions were you able to gather?\n",
    "total_submissions = len(df)\n",
    "print('Total April 2020 Submissions: {}'.format(total_submissions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author with most submissions for April 2020 in the subreddit: [deleted]\n"
     ]
    }
   ],
   "source": [
    "# Who has the most submissions?\n",
    "most_active = df['author'].value_counts().reset_index()[0:2]\n",
    "print('Author with most submissions for April 2020 in the subreddit: {}'.format(most_active['index'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top submission of April 2020 in the subreddit is: \n",
      "\n",
      "Working at an amusement park: unsuccessful backstabbing by girl_from_the_crypt\n"
     ]
    }
   ],
   "source": [
    "# Which submission has the highest score?\n",
    "top_submission = df.sort_values(by=['score'],ascending=False,ignore_index=True).head(1)\n",
    "print('The top submission of April 2020 in the subreddit is: \\n\\n{} by {}'.format(top_submission['title'][0],top_submission['author'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The post with the highest number of comments for April 2020 in the subreddit is: \n",
      "\n",
      "Working at an amusement park: kiss, swallow, turn by girl_from_the_crypt\n"
     ]
    }
   ],
   "source": [
    "#Which submission has the highest number of comments?\n",
    "top_commented = df.sort_values(by=['num_comments'],ascending=False,ignore_index=True).head(1)\n",
    "print('The post with the highest number of comments for April 2020 in the subreddit is: \\n\\n{} by {}'.format(top_commented['title'][0],top_commented['author'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most active day in April 2020: Thursday\n"
     ]
    }
   ],
   "source": [
    "# Which day of the week has the most submissions?\n",
    "df['dayname'] = pd.to_datetime(df['created_utc'], unit='s').dt.day_name() #creates dayname column\n",
    "most_active_day = df['dayname'].value_counts().reset_index()[0:2]\n",
    "print('Most active day in April 2020: {}'.format(most_active_day['index'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
